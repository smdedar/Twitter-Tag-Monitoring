{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "\n",
    "#For Clasification Model Built\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Algorithm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test data sets are imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset csv files and create pandas datframes\n",
    "\n",
    "train_df=pd.read_csv(\"train.csv\")\n",
    "test_df=pd.read_csv(\"1tweet_data.csv\", error_bad_lines=False)\n",
    "print(\"Train and Test data sets are imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Analysis and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to explore the train and test dataframes\n",
    "\n",
    "def explore_data(df):\n",
    "    print(\"-\"*100)\n",
    "    print(\"Shape of dataframe: \",df.shape)\n",
    "    print(\"Number of records in data set\",df.shape[0])\n",
    "    print(\"Information of Dataset\")\n",
    "    df.info()\n",
    "    print(\"-\"*100)\n",
    "    print(\"First 5 records of dataset:\")\n",
    "    return df.head(10)\n",
    "    print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape of dataframe:  (7613, 5)\n",
      "Number of records in data set 7613\n",
      "Information of Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "----------------------------------------------------------------------------------------------------\n",
      "First 5 records of dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape of dataframe:  (100, 36)\n",
      "Number of records in data set 100\n",
      "Information of Dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 36 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               100 non-null    float64\n",
      " 1   conversation_id  100 non-null    float64\n",
      " 2   created_at       100 non-null    object \n",
      " 3   date             100 non-null    object \n",
      " 4   time             100 non-null    object \n",
      " 5   timezone         100 non-null    int64  \n",
      " 6   user_id          100 non-null    float64\n",
      " 7   username         100 non-null    object \n",
      " 8   name             100 non-null    object \n",
      " 9   place            0 non-null      float64\n",
      " 10  text             100 non-null    object \n",
      " 11  language         100 non-null    object \n",
      " 12  mentions         100 non-null    object \n",
      " 13  urls             100 non-null    object \n",
      " 14  photos           100 non-null    object \n",
      " 15  replies_count    100 non-null    int64  \n",
      " 16  retweets_count   100 non-null    int64  \n",
      " 17  likes_count      100 non-null    int64  \n",
      " 18  hashtags         100 non-null    object \n",
      " 19  cashtags         100 non-null    object \n",
      " 20  link             100 non-null    object \n",
      " 21  retweet          100 non-null    bool   \n",
      " 22  quote_url        15 non-null     object \n",
      " 23  video            100 non-null    int64  \n",
      " 24  thumbnail        13 non-null     object \n",
      " 25  near             0 non-null      float64\n",
      " 26  geo              0 non-null      float64\n",
      " 27  source           0 non-null      float64\n",
      " 28  user_rt_id       0 non-null      float64\n",
      " 29  user_rt          0 non-null      float64\n",
      " 30  retweet_id       0 non-null      float64\n",
      " 31  reply_to         100 non-null    object \n",
      " 32  retweet_date     0 non-null      float64\n",
      " 33  translate        0 non-null      float64\n",
      " 34  trans_src        0 non-null      float64\n",
      " 35  trans_dest       0 non-null      float64\n",
      "dtypes: bool(1), float64(14), int64(5), object(16)\n",
      "memory usage: 27.6+ KB\n",
      "----------------------------------------------------------------------------------------------------\n",
      "First 5 records of dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>2021-01-11 20:10:44 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:10:44</td>\n",
       "      <td>600</td>\n",
       "      <td>9.607090e+07</td>\n",
       "      <td>falcolm</td>\n",
       "      <td>Anthony D Falcolm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'seanhannity', 'name': 'Sean ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.347610e+18</td>\n",
       "      <td>2021-01-11 20:08:58 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:08:58</td>\n",
       "      <td>600</td>\n",
       "      <td>8.544870e+17</td>\n",
       "      <td>notmyprez2020</td>\n",
       "      <td>Seeclearly61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Mike_Pence', 'name': 'Mike P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>2021-01-11 20:08:50 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:08:50</td>\n",
       "      <td>600</td>\n",
       "      <td>2.751025e+09</td>\n",
       "      <td>eddysr1728</td>\n",
       "      <td>Scott Edwards</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348440e+18</td>\n",
       "      <td>2021-01-11 20:08:16 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:08:16</td>\n",
       "      <td>600</td>\n",
       "      <td>1.304810e+18</td>\n",
       "      <td>freedom_free85</td>\n",
       "      <td>Conservative_by_choice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'mehdirhasan', 'name': 'Mehdi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>2021-01-11 20:06:09 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:06:09</td>\n",
       "      <td>600</td>\n",
       "      <td>5.986469e+08</td>\n",
       "      <td>dariusdeanhilli</td>\n",
       "      <td>Darius Dean Hill II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348430e+18</td>\n",
       "      <td>2021-01-11 20:02:07 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:02:07</td>\n",
       "      <td>600</td>\n",
       "      <td>7.636888e+08</td>\n",
       "      <td>petelu1456</td>\n",
       "      <td>dockbuilder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'juliettekayyem', 'name': 'Ju...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348600e+18</td>\n",
       "      <td>2021-01-11 20:01:32 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:01:32</td>\n",
       "      <td>600</td>\n",
       "      <td>1.127030e+18</td>\n",
       "      <td>brucemi10213461</td>\n",
       "      <td>Bruce Miller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'sydneypersing', 'name': 'Syd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348540e+18</td>\n",
       "      <td>2021-01-11 20:00:35 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>20:00:35</td>\n",
       "      <td>600</td>\n",
       "      <td>8.810170e+17</td>\n",
       "      <td>susanhyden5</td>\n",
       "      <td>Susan Hyden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'donwinslow', 'name': 'Don Wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>2021-01-11 19:59:44 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>19:59:44</td>\n",
       "      <td>600</td>\n",
       "      <td>1.248030e+09</td>\n",
       "      <td>flyme2themoon15</td>\n",
       "      <td>Naomi S.S.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.348630e+18</td>\n",
       "      <td>1.348490e+18</td>\n",
       "      <td>2021-01-11 19:59:28 Bangladesh Standard Time</td>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>19:59:28</td>\n",
       "      <td>600</td>\n",
       "      <td>2.696499e+07</td>\n",
       "      <td>swirlz31</td>\n",
       "      <td>Tanya J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'balleralert', 'name': 'Balle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  conversation_id  \\\n",
       "0  1.348630e+18     1.348630e+18   \n",
       "1  1.348630e+18     1.347610e+18   \n",
       "2  1.348630e+18     1.348630e+18   \n",
       "3  1.348630e+18     1.348440e+18   \n",
       "4  1.348630e+18     1.348630e+18   \n",
       "5  1.348630e+18     1.348430e+18   \n",
       "6  1.348630e+18     1.348600e+18   \n",
       "7  1.348630e+18     1.348540e+18   \n",
       "8  1.348630e+18     1.348630e+18   \n",
       "9  1.348630e+18     1.348490e+18   \n",
       "\n",
       "                                     created_at        date      time  \\\n",
       "0  2021-01-11 20:10:44 Bangladesh Standard Time  11/01/2021  20:10:44   \n",
       "1  2021-01-11 20:08:58 Bangladesh Standard Time  11/01/2021  20:08:58   \n",
       "2  2021-01-11 20:08:50 Bangladesh Standard Time  11/01/2021  20:08:50   \n",
       "3  2021-01-11 20:08:16 Bangladesh Standard Time  11/01/2021  20:08:16   \n",
       "4  2021-01-11 20:06:09 Bangladesh Standard Time  11/01/2021  20:06:09   \n",
       "5  2021-01-11 20:02:07 Bangladesh Standard Time  11/01/2021  20:02:07   \n",
       "6  2021-01-11 20:01:32 Bangladesh Standard Time  11/01/2021  20:01:32   \n",
       "7  2021-01-11 20:00:35 Bangladesh Standard Time  11/01/2021  20:00:35   \n",
       "8  2021-01-11 19:59:44 Bangladesh Standard Time  11/01/2021  19:59:44   \n",
       "9  2021-01-11 19:59:28 Bangladesh Standard Time  11/01/2021  19:59:28   \n",
       "\n",
       "   timezone       user_id         username                    name  place  \\\n",
       "0       600  9.607090e+07          falcolm       Anthony D Falcolm    NaN   \n",
       "1       600  8.544870e+17    notmyprez2020            Seeclearly61    NaN   \n",
       "2       600  2.751025e+09       eddysr1728           Scott Edwards    NaN   \n",
       "3       600  1.304810e+18   freedom_free85  Conservative_by_choice    NaN   \n",
       "4       600  5.986469e+08  dariusdeanhilli     Darius Dean Hill II    NaN   \n",
       "5       600  7.636888e+08       petelu1456             dockbuilder    NaN   \n",
       "6       600  1.127030e+18  brucemi10213461            Bruce Miller    NaN   \n",
       "7       600  8.810170e+17      susanhyden5             Susan Hyden    NaN   \n",
       "8       600  1.248030e+09  flyme2themoon15              Naomi S.S.    NaN   \n",
       "9       600  2.696499e+07         swirlz31                 Tanya J    NaN   \n",
       "\n",
       "   ... geo source user_rt_id user_rt retweet_id  \\\n",
       "0  ... NaN    NaN        NaN     NaN        NaN   \n",
       "1  ... NaN    NaN        NaN     NaN        NaN   \n",
       "2  ... NaN    NaN        NaN     NaN        NaN   \n",
       "3  ... NaN    NaN        NaN     NaN        NaN   \n",
       "4  ... NaN    NaN        NaN     NaN        NaN   \n",
       "5  ... NaN    NaN        NaN     NaN        NaN   \n",
       "6  ... NaN    NaN        NaN     NaN        NaN   \n",
       "7  ... NaN    NaN        NaN     NaN        NaN   \n",
       "8  ... NaN    NaN        NaN     NaN        NaN   \n",
       "9  ... NaN    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0  [{'screen_name': 'seanhannity', 'name': 'Sean ...           NaN        NaN   \n",
       "1  [{'screen_name': 'Mike_Pence', 'name': 'Mike P...           NaN        NaN   \n",
       "2                                                 []           NaN        NaN   \n",
       "3  [{'screen_name': 'mehdirhasan', 'name': 'Mehdi...           NaN        NaN   \n",
       "4                                                 []           NaN        NaN   \n",
       "5  [{'screen_name': 'juliettekayyem', 'name': 'Ju...           NaN        NaN   \n",
       "6  [{'screen_name': 'sydneypersing', 'name': 'Syd...           NaN        NaN   \n",
       "7  [{'screen_name': 'donwinslow', 'name': 'Don Wi...           NaN        NaN   \n",
       "8                                                 []           NaN        NaN   \n",
       "9  [{'screen_name': 'balleralert', 'name': 'Balle...           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "5       NaN        NaN  \n",
       "6       NaN        NaN  \n",
       "7       NaN        NaN  \n",
       "8       NaN        NaN  \n",
       "9       NaN        NaN  \n",
       "\n",
       "[10 rows x 36 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_data(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Normalization\n",
    "- Removing URL\n",
    "- Removing all irrelevant characters (Numbers and Punctuation)\n",
    "- Convert all characters into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1=train_df.copy()\n",
    "test_df1=test_df.copy()\n",
    "\n",
    "\n",
    "train_df1['text'] = train_df1['text'].apply(lambda x: clean_text(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_after_preprocess(before_text,after_text):\n",
    "    print(\"-\"*50)\n",
    "    print(\"Before Clean Text\")\n",
    "    print(\"-\"*50)\n",
    "    print(before_text.head(10))\n",
    "    print(\"-\"*50)\n",
    "    print(\"After Clean Text\")\n",
    "    print(\"-\"*50)\n",
    "    print(after_text.head(10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text_after_preprocess(test_df['text'],test_df1['text'])\n",
    "# text_after_preprocess(train_df['text'],train_df1['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Tokenize the training and the test dataset copies with RegEx tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "train_df1['text'] = train_df1['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1['text'].head(5)\n",
    "# test_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words Function\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: remove_stopwords(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1['text'].head(5)\n",
    "# test_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Convert the list of tokens into back to the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(text):\n",
    "    all_text = ' '.join(text)\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: combine_text(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: combine_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df1['text'].head(5)\n",
    "# train_df1['text'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lem(text):\n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemm_text =  \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    return lemm_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1['text'] = train_df1['text'].apply(lambda x: stem_lem(x))\n",
    "test_df1['text'] = test_df1['text'].apply(lambda x: stem_lem(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorization of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "train_cv = count_vectorizer.fit_transform(train_df1['text'])\n",
    "test_cv = count_vectorizer.transform(test_df1[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text using TFIDF\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tf = tfidf.fit_transform(train_df1['text'])\n",
    "test_tf = tfidf.transform(test_df1[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model List For Classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split TFDIF vectorize data\n",
    "\n",
    "x_train_tf,x_test_tf,y_train_tf,y_test_tf = train_test_split(train_tf,train_df.target,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Classifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84       849\n",
      "           1       0.85      0.66      0.74       674\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After all classifires test LogisticRegression() with TfidfVectorizer work best\n",
    "\n",
    "clf_logreg = LogisticRegression(C=1.0,penalty = 'l2',solver='lbfgs')\n",
    "clf_logreg.fit(x_train_tf, y_train_tf)\n",
    "prediction = clf_logreg.predict(x_test_tf)\n",
    "confusion_matrix(y_test_tf,prediction)\n",
    "print(classification_report(y_test_tf,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(file_loc,model,text_vector):\n",
    "    \n",
    "    sub_df = pd.read_csv(file_loc)\n",
    "    sub_df['target'] = model.predict(text_vector)\n",
    "    sub_df.to_csv(\"21tweet_data.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = '1tweet_data.csv'\n",
    "test_vector = test_tf\n",
    "submission(file_loc,clf_logreg,test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
